{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume WINDOWS\n",
      "Volume serial number is 1213-81F0\n",
      "C:.\n",
      "ÃÄÄÄ.ipynb_checkpoints\n",
      "ÃÄÄÄaclImdb\n",
      "³   ÃÄÄÄtest\n",
      "³   ³   ÃÄÄÄneg\n",
      "³   ³   ÀÄÄÄpos\n",
      "³   ÀÄÄÄtrain\n",
      "³       ÃÄÄÄneg\n",
      "³       ÃÄÄÄpos\n",
      "³       ÀÄÄÄunsup\n",
      "ÃÄÄÄcache\n",
      "³   ÀÄÄÄjoblib\n",
      "ÀÄÄÄ__pycache__\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasetssets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_train = load_files('aclImdb/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.<br /><br />Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. <br /><br />I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\"\n"
     ]
    }
   ],
   "source": [
    "text_train,y_train = reviews_train.data,reviews_train.target\n",
    "print(text_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\",b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_test = load_files('aclImdb/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_test,y_test = reviews_test.data,reviews_test.target\n",
    "text_test = [doc.replace(b\"<br />\",b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing as bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulry content :\n",
      " {'dont': 3, 'think': 10, 'it': 8, 'is': 7, 'great': 4, 'idea': 6, 'to': 11, 'stumble': 9, 'upon': 12, 'an': 1, 'but': 2, 'having': 5, 'always': 0}\n",
      "[[0 1 0 1 1 0 2 1 1 1 1 1 1]\n",
      " [1 1 1 0 1 1 1 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "## Example to use tokenizers\n",
    "bards_words = ['I dont think it is a  great idea to stumble upon an idea' ,\n",
    "              'but having an idea is always great']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect =CountVectorizer()\n",
    "vect.fit(bards_words);\n",
    "print('Vocabulry content :\\n',vect.vocabulary_)\n",
    "\n",
    "## creatin a bag\n",
    "bag_of_words = vect.transform(bards_words)\n",
    "print(bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'aesir',\n",
       " 'aquarian',\n",
       " 'barking',\n",
       " 'blustering',\n",
       " 'bête',\n",
       " 'chicanery',\n",
       " 'condensing',\n",
       " 'cunning',\n",
       " 'detox',\n",
       " 'draper',\n",
       " 'enshrined',\n",
       " 'favorit',\n",
       " 'freezer',\n",
       " 'goldman',\n",
       " 'hasan',\n",
       " 'huitieme',\n",
       " 'intelligible',\n",
       " 'kantrowitz',\n",
       " 'lawful',\n",
       " 'maars',\n",
       " 'megalunged',\n",
       " 'mostey',\n",
       " 'norrland',\n",
       " 'padilla',\n",
       " 'pincher',\n",
       " 'promisingly',\n",
       " 'receptionist',\n",
       " 'rivals',\n",
       " 'schnaas',\n",
       " 'shunning',\n",
       " 'sparse',\n",
       " 'subset',\n",
       " 'temptations',\n",
       " 'treatises',\n",
       " 'unproven',\n",
       " 'walkman',\n",
       " 'xylophonist']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.88132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scores = cross_val_score(LogisticRegression(),X_train,y_train,cv=5)\n",
    "print('Accuracy ',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88816\n",
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {  'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(),param_grid,cv=5,n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test SCore 0.87892\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print('Test SCore',grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using those tokens that appear in at least five documents\n",
    "vect = CountVectorizer(min_df= 5).fit(text_train)\n",
    "X_train = vect.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '007', '00s', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '100', '1000', '100th', '101', '102', '103']\n",
      "['00', 'affections', 'appropriately', 'barbra', 'blurbs', 'butchered', 'cheese', 'commitment', 'courts', 'deconstructed', 'disgraceful', 'dvds', 'eschews', 'fell', 'freezer', 'goriest', 'hauser', 'hungary', 'insinuate', 'juggle', 'leering', 'maelstrom', 'messiah', 'music', 'occasional', 'parking', 'pleasantville', 'pronunciation', 'recipient', 'reviews', 'sas', 'shea', 'sneers', 'steiger', 'swastika', 'thrusting', 'tvs', 'vampyre', 'westerns']\n"
     ]
    }
   ],
   "source": [
    "feature_names =vect.get_feature_names()\n",
    "print(feature_names[:20])\n",
    "print(feature_names[::700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88812\n",
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid,cv=5,n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## getting rid off too frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'she',\n",
       " 'before',\n",
       " 'hence',\n",
       " 'but',\n",
       " 'call',\n",
       " 'twenty',\n",
       " 'thick',\n",
       " 'very',\n",
       " 'could',\n",
       " 'been',\n",
       " 'so',\n",
       " 'con',\n",
       " 'amongst',\n",
       " 're',\n",
       " 'two']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "list(ENGLISH_STOP_WORDS)[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
